{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe9faf41",
   "metadata": {},
   "source": [
    "# 决策树（Decision Tree）\n",
    "决策树是一种常用的监督学习算法，适用于分类和回归任务。\n",
    "\n",
    "决策树通过树状结构来表示决策过程，每个内部节点代表一个特征或属性的测试，每个分支代表测试结果的输出，而每个叶节点则代表最终的决策或预测结果。\n",
    "\n",
    "### 决策树的基本概念\n",
    "- **节点（Node）**：树中的每个点称为节点。根节点是树的起点，内部节点是进行决策的节点，叶节点是最终的决策结果。\n",
    "- **分支（Branch）**：从一个节点到另一个节点的路径称为分支。\n",
    "- **分裂（Split）**：根据某个特征将数据划分为不同子集的过程称为分裂。\n",
    "- **纯度（Purity）**：衡量一个子集中样本的同质性，纯度越高，说明子集内样本越相似。常用的纯度指标包括信息增益、基尼指数和均方误差。\n",
    "\n",
    "### 决策树的工作原理\n",
    "决策树通过递归地将数据集划分为更小的子集来构建树。具体步骤如下：\n",
    "1. **选择最佳特征**：根据某种准则（如信息增益、基尼指数等）选择一个特征来分裂数据集。\n",
    "2. **分裂数据集**：根据选择的特征将数据集划分为多个子集。\n",
    "3. **递归构建子树**：对每个子集重复上述过程，直到满足停止条件（如达到最大深度、子集纯度足够高等）。\n",
    "4. **生成叶节点**：当满足停止条件时，创建叶节点并分配预测结果。\n",
    "\n",
    "### 决策树的构建标准\n",
    "在构建决策树时，需要选择最佳特征进行分割，常见的标准有：\n",
    "#### 1. 信息增益（Information Gain）\n",
    "用于分类问题，衡量通过某个特征进行分裂后信息的不确定性减少程度。信息增益越大，说明该特征越适合用于分裂数据集。计算公式为：\n",
    "$$IG(D, A) = Entropy(D) - \\sum_{v \\in Values(A)} \\frac{|D_v|}{|D|} Entropy(D_v)$$\n",
    "- $Entropy(D)$：数据集D的熵\n",
    "- $Entropy(D_v)$：子集D_v的熵\n",
    "- $D_v$：特征A取值为v的子集\n",
    "- $A$：用于分裂的数据集特征\n",
    "- $Values(A)$：特征A的所有可能取值\n",
    "- $|D|$：数据集D的样本数量\n",
    "- $|D_v|$：子集D_v的样本数量\n",
    "\n",
    "#### 2. 基尼指数（Gini Index）\n",
    "用于分类问题，衡量数据集的纯度。基尼指数越小，说明数据集越纯。计算公式为：\n",
    "$$Gini(D) = 1 - \\sum_{k=1}^{C} p_k^2$$\n",
    "- $p_k$：类别k在数据集D中的比例\n",
    "- $C$：类别的总数\n",
    "\n",
    "#### 3. 均方误差（Mean Squared Error, MSE）\n",
    "用于回归问题，衡量预测值与真实值之间的差异。均方误差越小，说明模型的预测效果越好。计算公式为：\n",
    "$$MSE = \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2$$\n",
    "- $y_i$：真实值\n",
    "- $\\hat{y}_i$：预测值\n",
    "- $n$：样本数量\n",
    "\n",
    "### 决策树的优缺点\n",
    "#### 优点\n",
    "- 易于理解和解释，决策过程可视化。\n",
    "- 能够处理多种类型的数据（数值型和类别型）。\n",
    "- 不需要大量的数据预处理，如归一化或标准化。\n",
    "\n",
    "#### 缺点\n",
    "- 容易过拟合，尤其是在树深度较大时。\n",
    "- 对噪声和异常值敏感。\n",
    "- 决策边界可能不够平滑，导致泛化能力较差。\n",
    "- 不稳定，对数据的小变化可能导致树结构的显著变化。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1de5a4",
   "metadata": {},
   "source": [
    "## Implementation of Decision Tree using Python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "213d5098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy: 1.00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'iris_decision_tree.pdf'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import export_graphviz\n",
    "import graphviz\n",
    "\n",
    "\n",
    "# load iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# create decision tree classifier\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# train the model\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# predict on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Model accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# export decision tree to dot file format\n",
    "dot_data = export_graphviz(clf, out_file=None, \n",
    "                           feature_names=iris.feature_names,  \n",
    "                           class_names=iris.target_names,  \n",
    "                           filled=True, rounded=True,  \n",
    "                           special_characters=True)\n",
    "\n",
    "# render decision tree using graphviz\n",
    "graph = graphviz.Source(dot_data)\n",
    "graph.render(\"iris_decision_tree\")  # save as PDF file\n",
    "graph.view()  # view in browser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3867c4fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sklearn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
