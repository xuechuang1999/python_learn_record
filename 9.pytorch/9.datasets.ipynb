{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97b1da80",
   "metadata": {},
   "source": [
    "# Pytorch 数据集\n",
    "在深度学习任务中，数据加载和处理是至关重要的。\n",
    "\n",
    "Pytorch提供了一个强大的数据加载和处理的工具，`torch.utils.data`模块。这个模块提供了一个抽象的接口来处理数据集和数据加载器。其包含的工具主要有：\n",
    "- `torch.utils.data.Dataset`：一个抽象类，表示一个数据集，需要自定义并实现`__len__`和`__getitem__`（按索引获取样本）方法；\n",
    "- `torch.utils.data.DataLoader`：封装`Dataset`的迭代器，提供批处理、打乱、并行加载等功能，便于数据输入模型训练；\n",
    "- `torch.utils.data.TensorDataset`：基于Tensor的简单数据集，适用于小型数据集，适合处理数据-标签对，直接支持批处理和迭代；\n",
    "- `torchvision.datasets.ImageFolder`：从文件夹加载图像数据，每个子文件夹代表一个类别，适用于图像分类任务；\n",
    "- `torchvision.transforms`：用于图像预处理的工具，提供了多种常用的图像变换操作，如裁剪、缩放、翻转、归一化等；\n",
    "- `torchvision.datasets`：提供了多种常用的数据集，如MNIST、CIFAR-10等，方便快速加载和使用；\n",
    "- `torch.utils.data.random_split`：用于将数据集随机划分为训练集和验证集，便于模型评估；\n",
    "- `torch.utils.data.ConcatDataset`：用于将多个数据集合并为一个数据集，便于处理多个数据源；\n",
    "- `torch.utils.data.Subset`：用于从数据集中获取子集，便于处理大规模数据集；\n",
    "\n",
    "## 1. Pytorch 内置数据集\n",
    "pytorch通过`torchvision.datasets`模块提供了许多常用的数据集，例如：\n",
    "- MNIST：手写数字图像数据集，用于图像分类任务；\n",
    "- CIFAR-10：小型图像数据集，包含10个类别的60000张32x32彩色图像，用于图像分类任务；\n",
    "- CIFAR-100：小型图像数据集，包含100个类别的60000张32x32彩色图像，用于图像分类任务；\n",
    "- COCO：大型图像数据集，包含80个类别的330000张图像和2.5M个目标实例，用于目标检测和分割任务；\n",
    "- ImageNet：大型图像数据集，包含1000个类别的1400000张图像，用于图像分类和物体检测任务；\n",
    "- STL-10：小型图像数据集，包含10个类别的10000张32x32彩色图像，用于图像分类任务；\n",
    "- Cityscapes：大型图像数据集，包含19个类别的5000张高分辨率街景图像，用于语义分割任务；\n",
    "- SQUAD：用于机器阅读理解任务的数据集，包含100000个问题和答案对；\n",
    "- IMDB：用于情感分析任务的数据集，包含50000条影评文本和对应的情感标签；\n",
    "- AG News：用于文本分类任务的数据集，包含120000条新闻文本和对应的类别标签；\n",
    "\n",
    "## 2. torchvision和torchtext\n",
    "- `torchvision`：一个图像库，提供了图片数据处理相关的API和数据接口，包括数据集加载函数和常用的图像变换操作；\n",
    "- `torchtext`：一个文本库，提供了文本数据处理相关的API和数据接口，包括数据预处理和数据加载的方式；\n",
    "\n",
    "## 3. `torch.tuils.data.Dataset`\n",
    "`Dataset`是一个抽象类，用于表示一个数据集。\n",
    "\n",
    "用户需要自定义一个类，继承`Dataset`类，并重写以下方法：\n",
    "- `__init__`：初始化数据集，通常用于加载数据和标签；\n",
    "- `__len__`：返回数据集的大小；\n",
    "- `__getitem__`：根据索引获取数据和标签，通常用于返回一个样本的数据和标签；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5636dcdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 100\n",
      "First sample: (tensor([-0.9653, -0.4638,  1.0233,  0.3844,  1.1839]), tensor(0))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# self defined dataset\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        # Initialize the dataset with data and labels\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return the number of samples in the dataset\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get the data and label for a given index\n",
    "        sample = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "        return sample, label\n",
    "    \n",
    "# generate the example data\n",
    "data = torch.randn(100, 5)             # 100 samples, 5 features for each\n",
    "labels = torch.randint(0, 2, (100,))   # binary labels (0 or 1)\n",
    "\n",
    "# instantiate the dataset\n",
    "dataset = MyDataset(data, labels)\n",
    "\n",
    "# test the dataset\n",
    "print(f\"Number of samples: {len(dataset)}\")\n",
    "print(f\"First sample: {dataset[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37db6389",
   "metadata": {},
   "source": [
    "## 4. `torch.utils.data.DataLoader`\n",
    "`DataLoader`是pytorch提供的数据加载器，用于批量加载数据集。其提供了以下功能：\n",
    "- 批量加载数据：可以指定每个批次的大小`batch_size`；\n",
    "- 打乱数据：可以在每个`epoch`开始时打乱数据`shuffle=True`，增加模型的泛化能力；\n",
    "- 多线程加载：可以使用多个子进程并行加载数据，`num_workers`参数可以指定使用的子进程数量，提高数据加载效率；\n",
    "- 迭代访问：可以使用`for`循环迭代访问数据集，返回每个批次的数据和标签；\n",
    "- 自动填充：可以自动填充不完整的批次，确保每个批次的大小一致；"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be6822f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1:\n",
      "Data: tensor([[-1.2374, -0.8510,  0.5050,  1.0553, -0.9911],\n",
      "        [-0.0390,  0.5259, -1.4702,  0.8122, -0.2769],\n",
      "        [-0.7355, -0.0571, -0.0048,  0.4285,  0.4695],\n",
      "        [ 0.0878, -0.2396, -0.5731, -0.0430, -1.0814],\n",
      "        [-1.0058, -0.6285, -0.2464, -0.5730, -0.8918],\n",
      "        [ 0.4183,  0.4852, -0.7359, -0.1474, -0.4360],\n",
      "        [-0.8915, -0.2917, -0.4202, -0.1014, -0.3616],\n",
      "        [ 1.3316, -0.3271, -2.7973,  1.4087, -0.6980],\n",
      "        [ 1.0853, -0.1313,  0.0483, -2.2979, -0.5655],\n",
      "        [ 0.5651,  0.0771, -1.7851, -2.9000, -1.0320]])\n",
      "Labels: tensor([1, 0, 0, 1, 1, 1, 0, 0, 1, 0])\n",
      "Batch 2:\n",
      "Data: tensor([[-0.0587, -1.2635, -0.1506, -1.4105, -0.8655],\n",
      "        [-1.4113, -0.7016,  1.1347, -0.5281, -1.2413],\n",
      "        [ 0.6348, -0.0290,  1.0258, -1.0792, -0.4326],\n",
      "        [ 0.2605, -0.3408, -0.3078,  1.5287, -0.6771],\n",
      "        [-1.0151,  0.2030,  1.2668, -1.5381, -1.1854],\n",
      "        [-1.0034,  0.1417, -2.0599, -1.0575, -0.1368],\n",
      "        [ 2.4683, -1.0232,  1.2880,  0.2080,  0.5080],\n",
      "        [ 1.8505, -0.1241,  0.0048, -0.5954, -0.3554],\n",
      "        [ 0.1630,  0.6404,  1.6024, -1.4262,  0.9322],\n",
      "        [ 0.0678,  0.6753, -0.0045, -0.1697, -0.7426]])\n",
      "Labels: tensor([1, 0, 0, 0, 0, 0, 1, 0, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# self defined dataset\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        # Initialize the dataset with data and labels\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return the number of samples in the dataset\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get the data and label for a given index\n",
    "        sample = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "        return sample, label\n",
    "\n",
    "# generate the example data\n",
    "data = torch.randn(100, 5)             # 100 samples, 5 features for each\n",
    "labels = torch.randint(0, 2, (100,))   # binary labels (0 or 1)\n",
    "\n",
    "# instantiate the dataset\n",
    "dataset = MyDataset(data, labels)\n",
    "# create a DataLoader\n",
    "dataloader = DataLoader(dataset, batch_size=10, shuffle=True, num_workers=0)\n",
    "\n",
    "# traverse the DataLoader\n",
    "for batch_idx, (batch_data, batch_labels) in enumerate(dataloader):\n",
    "    print(f\"Batch {batch_idx + 1}:\")\n",
    "    print(f\"Data: {batch_data}\")\n",
    "    print(f\"Labels: {batch_labels}\")\n",
    "    # break after first batch for demonstration\n",
    "    if batch_idx == 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ca9b989",
   "metadata": {},
   "source": [
    "## 5. 使用内置数据集\n",
    "Pytorch提供了多个常用数据集，存放在`torchvision.datasets`模块中。使用这些数据集非常简单，只需要调用相应的函数即可。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05a6d855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the batch: torch.Size([64, 1, 28, 28])\n",
      "The size of the labels: tensor([9, 8, 0, 3, 3, 8, 0, 7, 8, 3, 6, 3, 8, 3, 7, 3, 8, 8, 7, 4, 2, 3, 1, 0,\n",
      "        9, 3, 0, 0, 1, 2, 2, 2, 2, 2, 4, 8, 0, 8, 2, 2, 1, 9, 6, 0, 0, 3, 1, 6,\n",
      "        8, 7, 7, 0, 1, 1, 9, 0, 6, 0, 7, 8, 7, 2, 6, 7])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# define data preprocessing\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),                  # convert to tensor\n",
    "    transforms.Normalize((0.5,), (0.5,))    # normalize to mean=0.5, std=0.5\n",
    "])\n",
    "\n",
    "# load the train dataset\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "\n",
    "# load data through DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
    "\n",
    "# check a batch of data\n",
    "data_iter = iter(train_loader)\n",
    "images, labels = next(data_iter)\n",
    "print(f\"The size of the batch: {images.shape}\")\n",
    "print(f\"The size of the labels: {labels}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555d1368",
   "metadata": {},
   "source": [
    "## 6. `Dataset`和`DataLoader`的自定义使用\n",
    "将一个CSV文件作为数据源，并通过自定义`Dataset`类和`DataLoader`类来加载数据。以下是一个简单的示例："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b6b2a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: tensor([[-1.1000,  0.8000,  1.5000],\n",
      "        [ 0.5000, -1.2000,  3.3000],\n",
      "        [ 1.2000,  2.1000, -3.0000],\n",
      "        [ 0.9000, -0.5000, -1.8000]])\n",
      "Labels: tensor([1., 1., 1., 0.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# self defined dataset\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, csv_file):\n",
    "        # Initialize the dataset with a CSV file\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return the number of samples in the dataset\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # use .iloc to ensure the data is in the correct format\n",
    "        row = self.data.iloc[idx]\n",
    "        # separate features and labels\n",
    "        features = torch.tensor(row.iloc[:-1].to_numpy(), dtype=torch.float32)\n",
    "        label = torch.tensor(row.iloc[-1], dtype=torch.float32)\n",
    "        return features, label\n",
    "    \n",
    "# instantiate the dataset\n",
    "dataset = MyDataset('./data/runoob_pytorch_data.csv')\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "# traverse the DataLoader\n",
    "for features, labels in dataloader:\n",
    "    print(f\"Features: {features}\")\n",
    "    print(f\"Labels: {labels}\")\n",
    "    # break after first batch for demonstration\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
