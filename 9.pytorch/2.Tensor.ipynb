{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d7f5114",
   "metadata": {},
   "source": [
    "# Pytorch 张量（Tensor）基础\n",
    "\n",
    "张量是一个多维数组。\n",
    "在 PyTorch 中，张量是数据的核心表示形式，类似于Numpy中的ndarray。但具有GPU加速的能力。\n",
    "\n",
    "张量支持多种数据类型（整型、浮点型、布尔型等），并且可以在 CPU 和 GPU 之间进行转换。\n",
    "\n",
    "张量的维度称为“轴”（axis），每个轴的大小称为“形状”（shape）。例如，一个形状为 (3, 4) 的张量表示有 3 行和 4 列的数据。\n",
    "\n",
    "![alt text](<assets/different_dimension_tensor.jpg>)\n",
    "\n",
    "- 0维张量：标量（scalar），例如一个数字 5。\n",
    "- 1维张量：向量（vector），例如 [1, 2, 3]。\n",
    "- 2维张量：矩阵（matrix），例如 [[1, 2], [3, 4]]。\n",
    "- 3维张量：立方体（cube），例如 [[[1, 2], [3, 4]], [[5, 6], [7, 8]]]。\n",
    "- 4维张量：立方体向量，例如 [[[[1, 2], [3, 4]], [[5, 6], [7, 8]]], [[[9, 10], [11, 12]], [[13, 14], [15, 16]]]]。\n",
    "- 5维张量：立方体矩阵，例如 [[[[[1, 2], [3, 4]], [[5, 6], [7, 8]]], [[[9, 10], [11, 12]], [[13, 14], [15, 16]]]], [[[[17, 18], [19, 20]], [[21, 22], [23, 24]]], [[[25, 26], [27, 28]], [[29, 30], [31, 32]]]]]。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfcd242",
   "metadata": {},
   "source": [
    "## 1. 创建张量\n",
    "\n",
    "|方法|说明|示例|\n",
    "|---|---|---|\n",
    "|`torch.tensor(data)`|从python列表或NumPy数组创建张量|`x = torch.tensor([[1, 2], [3, 4]])`|\n",
    "|`torch.zeros(size)`|创建全零张量|`x = torch.zeros((2, 3))`|\n",
    "|`torch.ones(size)`|创建全一张量|`x = torch.ones((2, 3))`|\n",
    "|`torch.empty(size)`|创建未初始化的张量|`x = torch.empty((2, 3))`|\n",
    "|`torch.rand(size)`|创建均匀分布的随机张量，值在[0,1)|`x = torch.rand((2, 3))`|\n",
    "|`torch.randn(size)`|创建正态分布的随机张量，均值为0，标准差为1|`x = torch.randn((2, 3))`|\n",
    "|`torch.arange(start, end, step)`|创建一个一维张量，包含从start到end（不包括end），步长为step的值|`x = torch.arange(0, 10, 2)`|\n",
    "|`torch.linspace(start, end, steps)`|创建一个一维张量，包含从start到end（包括end），均匀分布的steps个值|`x = torch.linspace(0, 1, 5)`|\n",
    "|`torch.eye(n)`|创建一个n x n的单位矩阵|`x = torch.eye(3)`|\n",
    "|`torch.from_numpy(ndarray)`|从NumPy数组创建张量|`x = torch.from_numpy(np.array([[1, 2], [3, 4]]))`|\n",
    "\n",
    "使用`torch.tensor()`函数，可以将一个列表或数组转换为张量："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dd46029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "tensor = torch.tensor([1, 2, 3, 4, 5])\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb139805",
   "metadata": {},
   "source": [
    "如果有一个NumPy数组，可以使用`torch.from_numpy()`函数将其转换为张量："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cd802f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3 4 5]\n",
      "tensor([1, 2, 3, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np_array = np.array([1, 2, 3, 4, 5])\n",
    "print(np_array)\n",
    "\n",
    "tensor = torch.from_numpy(np_array)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c97a1478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2D tensor (Matrix): \n",
      " tensor([[-9,  4,  2,  4],\n",
      "        [ 1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8]])\n",
      "Shape: torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "# create 2D tensor\n",
    "tensor_2D = torch.tensor([\n",
    "    [-9, 4, 2, 4],\n",
    "    [1, 2, 3, 4],\n",
    "    [5, 6, 7, 8]\n",
    "])\n",
    "\n",
    "print(\"2D tensor (Matrix): \\n\", tensor_2D)\n",
    "\n",
    "print(\"Shape:\", tensor_2D.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20388c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3D tensor: \n",
      " tensor([[[ -9,   4,   2,   4],\n",
      "         [  1,   2,   3,   4],\n",
      "         [  5,   6,   7,   8]],\n",
      "\n",
      "        [[  1,  14,  12,  14],\n",
      "         [ 11,  12,  13,  14],\n",
      "         [ 15,  16,  17,  18]],\n",
      "\n",
      "        [[-14,  -1,  -3,  -1],\n",
      "         [ -4,  -3,  -2,  -1],\n",
      "         [  0,   1,   2,   3]]])\n",
      "Shape: torch.Size([3, 3, 4])\n",
      "4D tensor: \n",
      " tensor([[[[ -9,   4,   2,   4],\n",
      "          [  1,   2,   3,   4],\n",
      "          [  5,   6,   7,   8]],\n",
      "\n",
      "         [[  1,  14,  12,  14],\n",
      "          [ 11,  12,  13,  14],\n",
      "          [ 15,  16,  17,  18]],\n",
      "\n",
      "         [[-14,  -1,  -3,  -1],\n",
      "          [ -4,  -3,  -2,  -1],\n",
      "          [  0,   1,   2,   3]]],\n",
      "\n",
      "\n",
      "        [[[  1,  14,  12,  14],\n",
      "          [ 11,  12,  13,  14],\n",
      "          [ 15,  16,  17,  18]],\n",
      "\n",
      "         [[ 11,  24,  22,  24],\n",
      "          [ 21,  22,  23,  24],\n",
      "          [ 25,  26,  27,  28]],\n",
      "\n",
      "         [[ -4,   9,   7,   9],\n",
      "          [  6,   7,   8,   9],\n",
      "          [ 10,  11,  12,  13]]],\n",
      "\n",
      "\n",
      "        [[[-14,  -1,  -3,  -1],\n",
      "          [ -4,  -3,  -2,  -1],\n",
      "          [  0,   1,   2,   3]],\n",
      "\n",
      "         [[ -4,   9,   7,   9],\n",
      "          [  6,   7,   8,   9],\n",
      "          [ 10,  11,  12,  13]],\n",
      "\n",
      "         [[-19,  -6,  -8,  -6],\n",
      "          [ -9,  -8,  -7,  -6],\n",
      "          [ -5,  -4,  -3,  -2]]]])\n",
      "Shape: torch.Size([3, 3, 3, 4])\n",
      "5D tensor: \n",
      " tensor([[[[[ -9,   4,   2,   4],\n",
      "           [  1,   2,   3,   4],\n",
      "           [  5,   6,   7,   8]],\n",
      "\n",
      "          [[  1,  14,  12,  14],\n",
      "           [ 11,  12,  13,  14],\n",
      "           [ 15,  16,  17,  18]],\n",
      "\n",
      "          [[-14,  -1,  -3,  -1],\n",
      "           [ -4,  -3,  -2,  -1],\n",
      "           [  0,   1,   2,   3]]],\n",
      "\n",
      "\n",
      "         [[[  1,  14,  12,  14],\n",
      "           [ 11,  12,  13,  14],\n",
      "           [ 15,  16,  17,  18]],\n",
      "\n",
      "          [[ 11,  24,  22,  24],\n",
      "           [ 21,  22,  23,  24],\n",
      "           [ 25,  26,  27,  28]],\n",
      "\n",
      "          [[ -4,   9,   7,   9],\n",
      "           [  6,   7,   8,   9],\n",
      "           [ 10,  11,  12,  13]]],\n",
      "\n",
      "\n",
      "         [[[-14,  -1,  -3,  -1],\n",
      "           [ -4,  -3,  -2,  -1],\n",
      "           [  0,   1,   2,   3]],\n",
      "\n",
      "          [[ -4,   9,   7,   9],\n",
      "           [  6,   7,   8,   9],\n",
      "           [ 10,  11,  12,  13]],\n",
      "\n",
      "          [[-19,  -6,  -8,  -6],\n",
      "           [ -9,  -8,  -7,  -6],\n",
      "           [ -5,  -4,  -3,  -2]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[  1,  14,  12,  14],\n",
      "           [ 11,  12,  13,  14],\n",
      "           [ 15,  16,  17,  18]],\n",
      "\n",
      "          [[ 11,  24,  22,  24],\n",
      "           [ 21,  22,  23,  24],\n",
      "           [ 25,  26,  27,  28]],\n",
      "\n",
      "          [[ -4,   9,   7,   9],\n",
      "           [  6,   7,   8,   9],\n",
      "           [ 10,  11,  12,  13]]],\n",
      "\n",
      "\n",
      "         [[[ 11,  24,  22,  24],\n",
      "           [ 21,  22,  23,  24],\n",
      "           [ 25,  26,  27,  28]],\n",
      "\n",
      "          [[ 21,  34,  32,  34],\n",
      "           [ 31,  32,  33,  34],\n",
      "           [ 35,  36,  37,  38]],\n",
      "\n",
      "          [[  6,  19,  17,  19],\n",
      "           [ 16,  17,  18,  19],\n",
      "           [ 20,  21,  22,  23]]],\n",
      "\n",
      "\n",
      "         [[[ -4,   9,   7,   9],\n",
      "           [  6,   7,   8,   9],\n",
      "           [ 10,  11,  12,  13]],\n",
      "\n",
      "          [[  6,  19,  17,  19],\n",
      "           [ 16,  17,  18,  19],\n",
      "           [ 20,  21,  22,  23]],\n",
      "\n",
      "          [[ -9,   4,   2,   4],\n",
      "           [  1,   2,   3,   4],\n",
      "           [  5,   6,   7,   8]]]],\n",
      "\n",
      "\n",
      "\n",
      "        [[[[-14,  -1,  -3,  -1],\n",
      "           [ -4,  -3,  -2,  -1],\n",
      "           [  0,   1,   2,   3]],\n",
      "\n",
      "          [[ -4,   9,   7,   9],\n",
      "           [  6,   7,   8,   9],\n",
      "           [ 10,  11,  12,  13]],\n",
      "\n",
      "          [[-19,  -6,  -8,  -6],\n",
      "           [ -9,  -8,  -7,  -6],\n",
      "           [ -5,  -4,  -3,  -2]]],\n",
      "\n",
      "\n",
      "         [[[ -4,   9,   7,   9],\n",
      "           [  6,   7,   8,   9],\n",
      "           [ 10,  11,  12,  13]],\n",
      "\n",
      "          [[  6,  19,  17,  19],\n",
      "           [ 16,  17,  18,  19],\n",
      "           [ 20,  21,  22,  23]],\n",
      "\n",
      "          [[ -9,   4,   2,   4],\n",
      "           [  1,   2,   3,   4],\n",
      "           [  5,   6,   7,   8]]],\n",
      "\n",
      "\n",
      "         [[[-19,  -6,  -8,  -6],\n",
      "           [ -9,  -8,  -7,  -6],\n",
      "           [ -5,  -4,  -3,  -2]],\n",
      "\n",
      "          [[ -9,   4,   2,   4],\n",
      "           [  1,   2,   3,   4],\n",
      "           [  5,   6,   7,   8]],\n",
      "\n",
      "          [[-24, -11, -13, -11],\n",
      "           [-14, -13, -12, -11],\n",
      "           [-10,  -9,  -8,  -7]]]]])\n",
      "Shape: torch.Size([3, 3, 3, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "# create other dimensions\n",
    "tensor_3D = torch.stack(\n",
    "    [tensor_2D, tensor_2D + 10, tensor_2D -5]\n",
    ")\n",
    "\n",
    "print(\"3D tensor: \\n\", tensor_3D)\n",
    "print(\"Shape:\", tensor_3D.shape)\n",
    "\n",
    "tensor_4D = torch.stack(\n",
    "    [tensor_3D, tensor_3D + 10, tensor_3D -5]\n",
    ")\n",
    "print(\"4D tensor: \\n\", tensor_4D)\n",
    "print(\"Shape:\", tensor_4D.shape)\n",
    "\n",
    "# create 5D tensor\n",
    "tensor_5D = torch.stack(\n",
    "    [tensor_4D, tensor_4D + 10, tensor_4D -5]\n",
    ")\n",
    "print(\"5D tensor: \\n\", tensor_5D)\n",
    "print(\"Shape:\", tensor_5D.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f6887b7",
   "metadata": {},
   "source": [
    "## 2. 张量属性\n",
    "张量有几个重要的属性：\n",
    "\n",
    "|属性|说明|示例|\n",
    "|---|---|---|\n",
    "|.shape|张量的形状|`tensor.shape`|\n",
    "|.size()|张量的大小|`tensor.size()`|\n",
    "|.dtype|张量的数据类型|`tensor.dtype`|\n",
    "|.device|张量所在的设备（CPU或GPU）|`tensor.device`|\n",
    "|.requires_grad|是否需要梯度计算|`tensor.requires_grad`|\n",
    "|.numel()|张量的元素个数|`tensor.numel()`|\n",
    "|.is_cuda|是否在GPU上|`tensor.is_cuda`|\n",
    "|.is_leaf|是否是叶子节点|`tensor.is_leaf`|\n",
    "|.T|转置张量|`tensor.T`|\n",
    "|.item()|获取标量值|`tensor.item()`|\n",
    "|.is_contiguous()|是否是连续的|`tensor.is_contiguous()`|\n",
    "|.storage()|返回张量的存储对象|`tensor.storage()`|\n",
    "|.stride()|返回张量的步幅|`tensor.stride()`|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64e0bb4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor:\n",
      " tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "Shape: torch.Size([2, 3])\n",
      "size: torch.Size([2, 3])\n",
      "Number of dimensions: 2\n",
      "Data type: torch.float32\n",
      "Device: cpu\n",
      "Number of elements: 6\n",
      "Element size (bytes): 4\n",
      "Data type: torch.float32\n",
      "Requires grad: False\n",
      "Is leaf: True\n",
      "Is sparse: False\n",
      "Is quantized: False\n",
      "Is complex: <built-in method is_complex of Tensor object at 0x0000024F6CEFEC90>\n",
      "Is contiguous: True\n",
      "Is CUDA: False\n",
      "Single value tensor: tensor(42)\n",
      "Transposed tensor:\n",
      " tensor([[1., 4.],\n",
      "        [2., 5.],\n",
      "        [3., 6.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# create 2D tensor\n",
    "tensor = torch.tensor([[1, 2, 3], [4, 5, 6]], dtype=torch.float32)\n",
    "print(\"Original tensor:\\n\", tensor)\n",
    "\n",
    "# tensor properties\n",
    "print(\"Shape:\", tensor.shape)\n",
    "print(\"size:\", tensor.size())\n",
    "print(\"Number of dimensions:\", tensor.ndim)\n",
    "print(\"Data type:\", tensor.dtype)\n",
    "print(\"Device:\", tensor.device)\n",
    "print(\"Number of elements:\", tensor.numel())\n",
    "print(\"Element size (bytes):\", tensor.element_size())\n",
    "print(\"Data type:\", tensor.dtype)\n",
    "print(\"Requires grad:\", tensor.requires_grad)\n",
    "print(\"Is leaf:\", tensor.is_leaf)\n",
    "print(\"Is sparse:\", tensor.is_sparse)\n",
    "print(\"Is quantized:\", tensor.is_quantized)\n",
    "print(\"Is complex:\", tensor.is_complex)\n",
    "print(\"Is contiguous:\", tensor.is_contiguous())\n",
    "print(\"Is CUDA:\", tensor.is_cuda)\n",
    "\n",
    "\n",
    "single_value = torch.tensor(42)\n",
    "print(\"Single value tensor:\", single_value)\n",
    "\n",
    "# inverse tensor\n",
    "tensor_T = tensor.T\n",
    "print(\"Transposed tensor:\\n\", tensor_T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f026237",
   "metadata": {},
   "source": [
    "## 3. 张量操作\n",
    "张量支持多种操作，包括数学运算、索引、切片、连接等\n",
    "\n",
    "基础操作：\n",
    "|操作|说明|示例|\n",
    "|---|---|---|\n",
    "|+ - * /|加、减、乘、除|`a + b`, `a - b`, `a * b`, `a / b`|\n",
    "|torch.matmul(a, b)|矩阵乘法|`z = torch.matmul(a, b)`|\n",
    "|torch.dot(a, b)|向量点乘，仅适用于1D张量|`z = torch.dot(a, b)`|\n",
    "|tensor.sum(x)|对张量的所有元素求和|`z = torch.sum(x)`|\n",
    "|tensor.mean(x)|对张量的所有元素求均值|`z = torch.mean(x)`|\n",
    "|tensor.max(x)|对张量的所有元素求最大值|`z = torch.max(x)`|\n",
    "|tensor.min(x)|对张量的所有元素求最小值|`z = torch.min(x)`|\n",
    "|tensor.argmax(x)|返回最大值的索引，指定维度|`z = torch.argmax(x, dim=1)`|\n",
    "|tensor.argmin(x)|返回最小值的索引，指定维度|`z = torch.argmin(x, dim=1)`|\n",
    "|tensor.softmax(x)|计算softmax（指定维度）|`z = torch.softmax(x, dim=1)`|\n",
    "\n",
    "形状操作：\n",
    "|操作|说明|示例|\n",
    "|---|---|---|\n",
    "|x.view(shape)|改变张量的形状（不改变数据）|`z = x.view(2, 3)`|\n",
    "|x.reshape(shape)|类似于view，但更灵活|`z = x.reshape(2, 3)`|\n",
    "|x.t()|转置张量|`z = x.t()`|\n",
    "|x.unsqueeze(dim)|在指定维度上增加一个维度|`z = x.unsqueeze(0)`|\n",
    "|x.squeeze(dim)|在指定维度上去掉一个维度|`z = x.squeeze(0)`|\n",
    "|torch.cat((x, y), dim)|在指定维度上连接两个张量|`z = torch.cat((x, y), dim=0)`|\n",
    "|torch.stack((x, y), dim)|在指定维度上堆叠两个张量|`z = torch.stack((x, y), dim=0)`|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef146c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor:\n",
      " tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "\n",
      "Indexing and slicing:\n",
      "First row: tensor([1., 2., 3.])\n",
      "First column: tensor([1., 4.])\n",
      "First row and first column: tensor(1.)\n",
      "First two rows: tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "Last row: tensor([4., 5., 6.])\n",
      "Last column: tensor([3., 6.])\n",
      "Last two rows: tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "Last two columns: tensor([[2., 3.],\n",
      "        [5., 6.]])\n",
      "First two rows and first two columns: tensor([[1., 2.],\n",
      "        [4., 5.]])\n",
      "First two rows and last two columns: tensor([[2., 3.],\n",
      "        [5., 6.]])\n",
      "Last two rows and first two columns: tensor([[1., 2.],\n",
      "        [4., 5.]])\n",
      "Last two rows and last two columns: tensor([[2., 3.],\n",
      "        [5., 6.]])\n",
      "\n",
      "Shape operations:\n",
      "Shape: torch.Size([2, 3])\n",
      "Reshaped tensor:\n",
      " tensor([[1., 2.],\n",
      "        [3., 4.],\n",
      "        [5., 6.]])\n",
      "Flattened tensor:\n",
      " tensor([1., 2., 3., 4., 5., 6.])\n",
      "\n",
      "Math operations:\n",
      "Addition 10:\n",
      " tensor([[11., 12., 13.],\n",
      "        [14., 15., 16.]])\n",
      "Multiplication 2:\n",
      " tensor([[ 2.,  4.,  6.],\n",
      "        [ 8., 10., 12.]])\n",
      "Sum of all elements: tensor(21.) 21.0\n",
      "Mean of all elements: tensor(3.5000) 3.5\n",
      "\n",
      "Other operations:\n",
      "Second tensor:\n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "Matrix multiply result:\n",
      " tensor([[ 6.,  6.],\n",
      "        [15., 15.]])\n",
      "\n",
      "Conditionals and screening:\n",
      "The boolean mask of tensor > 2:\n",
      " tensor([[False, False,  True],\n",
      "        [ True,  True,  True]])\n",
      "Filtered tensor (elements > 2):\n",
      " tensor([3., 4., 5., 6.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# create 2D tensor\n",
    "tensor = torch.tensor([[1, 2, 3], [4, 5, 6]], dtype=torch.float32)\n",
    "print(\"Original tensor:\\n\", tensor)\n",
    "\n",
    "# 1. index and slice operations\n",
    "print(\"\\nIndexing and slicing:\")\n",
    "print(\"First row:\", tensor[0])\n",
    "print(\"First column:\", tensor[:, 0])\n",
    "print(\"First row and first column:\", tensor[0, 0])\n",
    "print(\"First two rows:\", tensor[:2])\n",
    "print(\"Last row:\", tensor[-1])\n",
    "print(\"Last column:\", tensor[:, -1])\n",
    "print(\"Last two rows:\", tensor[-2:])\n",
    "print(\"Last two columns:\", tensor[:, -2:])\n",
    "print(\"First two rows and first two columns:\", tensor[:2, :2])\n",
    "print(\"First two rows and last two columns:\", tensor[:2, -2:])\n",
    "print(\"Last two rows and first two columns:\", tensor[-2:, :2])\n",
    "print(\"Last two rows and last two columns:\", tensor[-2:, -2:])\n",
    "\n",
    "\n",
    "# 2. shape operations\n",
    "print(\"\\nShape operations:\")\n",
    "print(\"Shape:\", tensor.shape)\n",
    "\n",
    "reshaped_tensor = tensor.view(3, 2)\n",
    "print(\"Reshaped tensor:\\n\", reshaped_tensor)\n",
    "\n",
    "flattened_tensor = tensor.flatten() # make the tensor to 1D\n",
    "print(\"Flattened tensor:\\n\", flattened_tensor)\n",
    "\n",
    "\n",
    "# 3. math operations\n",
    "print(\"\\nMath operations:\")\n",
    "tensor_add = tensor + 10\n",
    "print(\"Addition 10:\\n\", tensor_add)\n",
    "\n",
    "tensor_mul = tensor * 2\n",
    "print(\"Multiplication 2:\\n\", tensor_mul)\n",
    "\n",
    "tensor_sum = tensor.sum()\n",
    "print(\"Sum of all elements:\", tensor_sum, tensor_sum.item())\n",
    "\n",
    "tensor_mean = tensor.mean()\n",
    "print(\"Mean of all elements:\", tensor_mean, tensor_mean.item())\n",
    "\n",
    "\n",
    "# 4. other operations\n",
    "print(\"\\nOther operations:\")\n",
    "tensor2 = torch.tensor([[1, 1, 1], [1, 1, 1]], dtype=torch.float32)\n",
    "print(\"Second tensor:\\n\", tensor2)\n",
    "\n",
    "tensor_matmul = torch.matmul(tensor, tensor2.T)\n",
    "print(\"Matrix multiply result:\\n\", tensor_matmul)\n",
    "\n",
    "\n",
    "# 5. conditionals judge and screen\n",
    "print(\"\\nConditionals and screening:\")\n",
    "mask = tensor > 2          # create a boolean mask\n",
    "print(\"The boolean mask of tensor > 2:\\n\", mask)\n",
    "\n",
    "filtered_tensor = tensor[mask]  # filter the tensor using the mask\n",
    "print(\"Filtered tensor (elements > 2):\\n\", filtered_tensor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3d2bce",
   "metadata": {},
   "source": [
    "## 4. 张量的GPU加速\n",
    "将张量转移到GPU上，并检测是否可用："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8e6d5b58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "x = torch.tensor([1, 2, 3], device=device, dtype=torch.float32)\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e897ad",
   "metadata": {},
   "source": [
    "## 5. 张量与NumPy的互操作\n",
    "张量和NumPy数组之间可以相互转换：\n",
    "\n",
    "| 操作 | 说明 | 示例 |\n",
    "|---|---|---|\n",
    "| `torch.from_numpy(ndarray)` | 从NumPy数组创建张量 | `tensor = torch.from_numpy(np_array)` |\n",
    "| `tensor.numpy()` | 将张量转换为NumPy数组（仅限CPU张量） | `np_array = tensor.numpy()` |\n",
    "| `torch.save(tensor, 'file.pth')` | 保存张量到文件 | `torch.save(tensor, 'tensor.pth')` |\n",
    "| `torch.load('file.pth')` | 从文件加载张量 | `tensor = torch.load('tensor.pth')` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a36908ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Numpy ndarray to torch tensor:\n",
      "Numpy array:\n",
      " [[1 2 3]\n",
      " [4 5 6]]\n",
      "Torch tensor:\n",
      " tensor([[1, 2, 3],\n",
      "        [4, 5, 6]]) \n",
      "\n",
      "Edited numpy array:\n",
      " [[100   2   3]\n",
      " [  4   5   6]]\n",
      "Torch tensor after numpy array edit:\n",
      " tensor([[100,   2,   3],\n",
      "        [  4,   5,   6]]) \n",
      "\n",
      "2. Torch tensor to numpy ndarray:\n",
      "Torch tensor:\n",
      " tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "Numpy array:\n",
      " [[1 2 3]\n",
      " [4 5 6]] \n",
      "\n",
      "Edited torch tensor:\n",
      " tensor([[100,   2,   3],\n",
      "        [  4,   5,   6]])\n",
      "Numpy array after torch tensor edit:\n",
      " [[100   2   3]\n",
      " [  4   5   6]] \n",
      "\n",
      "3. Use torch.clone() to keep data is independent:\n",
      "Torch tensor:\n",
      " tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "Edited torch tensor:\n",
      " tensor([[0., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "Numpy array (independent):\n",
      " [[1. 2. 3.]\n",
      " [4. 5. 6.]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# 1. numpy ndarray to torch tensor\n",
    "print(\"1. Numpy ndarray to torch tensor:\")\n",
    "numpy_array = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "print(\"Numpy array:\\n\", numpy_array)\n",
    "torch_tensor = torch.from_numpy(numpy_array)\n",
    "print(\"Torch tensor:\\n\", torch_tensor, \"\\n\")\n",
    "\n",
    "# edit the numpy array, obersorve the change in torch tensor, which shares the same memory\n",
    "numpy_array[0, 0] = 100\n",
    "print(\"Edited numpy array:\\n\", numpy_array)\n",
    "print(\"Torch tensor after numpy array edit:\\n\", torch_tensor, \"\\n\")\n",
    "\n",
    "\n",
    "# 2. torch tensor to numpy ndarray\n",
    "print(\"2. Torch tensor to numpy ndarray:\")\n",
    "torch_tensor = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "print(\"Torch tensor:\\n\", torch_tensor)\n",
    "numpy_array = torch_tensor.numpy()\n",
    "print(\"Numpy array:\\n\", numpy_array, \"\\n\")\n",
    "\n",
    "# edit the torch tensor, obersorve the change in numpy array, which shares the same memory\n",
    "torch_tensor[0, 0] = 100\n",
    "print(\"Edited torch tensor:\\n\", torch_tensor)\n",
    "print(\"Numpy array after torch tensor edit:\\n\", numpy_array, \"\\n\")\n",
    "\n",
    "\n",
    "# 3. Notice: not share the same memory (need to copy)\n",
    "print(\"3. Use torch.clone() to keep data is independent:\")\n",
    "tensor_independent = torch.tensor([[1, 2, 3], [4, 5, 6]], dtype=torch.float32)\n",
    "numpy_independent = tensor_independent.clone().numpy()\n",
    "print(\"Torch tensor:\\n\", tensor_independent)\n",
    "tensor_independent[0, 0] = 0\n",
    "print(\"Edited torch tensor:\\n\", tensor_independent)\n",
    "print(\"Numpy array (independent):\\n\", numpy_independent, \"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
